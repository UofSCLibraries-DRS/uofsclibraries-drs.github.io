
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Multilingual NER 3 &#8212; USC Libraries - DRS Resources for Data Literacy</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'src/TextMining/NER-3';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/USC_Libraries_logo_horizontal_RGB_2C.png" class="logo__image only-light" alt="USC Libraries - DRS Resources for Data Literacy - Home"/>
    <script>document.write(`<img src="../../_static/USC_Libraries_logo_horizontal_RGB_2C.png" class="logo__image only-dark" alt="USC Libraries - DRS Resources for Data Literacy - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Wrangling with Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Python/BasicPython.html">Basic Python Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Python/IntermediatePython.html">Intermediate Python Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Python/PandasPython.html">Pandas Python Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DataProcessingBasics/DataCleaning_Basics.html">Data Cleaning Basics</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Wrangling with R</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../R_Code/Data_Wrangling.html">Data Wrangling with R</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Extraction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../API/API.html">Using APIs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Mining with Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="IntroductionTextAnalysis.html">Introduction to Text Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="AdvancedTextAnalysis.html">Advanced Text Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="MultiLingualNer.html">Named Entity Recognition (NER)</a></li>
<li class="toctree-l1"><a class="reference internal" href="TextPreprocessing/TextPreprocessingMethods.html">Example</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Mining with R</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview/Tidy_Text.html">Text Mining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Visualization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview/Charts.html">Bar, Line, Scatter Plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Data_Visualization/Maps.html">Creating Maps with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Data_Visualization/Seaborn_Basictutorial.html">Seaborn Basics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview/MachineLearning.html">Brief Overview</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">App Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview/AppDevelopment.html">App Development</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/UofSCLibraries-DRS/uofsclibraries-drs.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/UofSCLibraries-DRS/uofsclibraries-drs.github.io/issues/new?title=Issue%20on%20page%20%2Fsrc/TextMining/NER-3.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/src/TextMining/NER-3.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Multilingual NER 3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Multilingual NER 3</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#install-libraries">Install libraries</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-word-embeddings">Introduction to word embeddings</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributional-hypothesis">Distributional hypothesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">Word2Vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-vectors-in-spacy">Word vectors in SpaCy</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-machine-learning">Introduction to Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-machine-learning-pipeline">The machine learning pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-in-word2vec">ML in Word2Vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-evaluation">Training and evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ner-with-entityruler-vs-ml-ner">NER with EntityRuler vs. ML NER</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-an-nlp-model-with-an-entityruler-to-identify-the-spells">Create an NLP model with an EntityRuler to identify the spells</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-the-data">Preprocessing the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-the-patterns-to-be-added-to-the-entityruler">Creating the patterns to be added to the EntityRuler</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-nlp-model-using-ml-to-identify-the-spells">Train a NLP model using ML to identify the spells</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>This notebook was created by <a class="reference external" href="https://datascience.si.edu/people/dr-william-mattingly">William Mattingly</a> for the 2022 Text Analysis Pedagogy Institute, with support from the <a class="reference external" href="https://neh.gov">National Endowment for the Humanities</a>, <a class="reference external" href="https://labs.jstor.org/">JSTOR Labs</a>, and <a class="reference external" href="https://new.library.arizona.edu/">University of Arizona Libraries</a> and <a class="reference external" href="https://ischool.illinois.edu/people/zoe-leblanc">Zoe LeBlanc</a> for the 2021 Text Analysis Pedagogy Institute, with support from the <a class="reference external" href="https://neh.gov">National Endowment for the Humanities</a>, <a class="reference external" href="https://labs.jstor.org/">JSTOR Labs</a>, and <a class="reference external" href="https://library.virginia.edu">University of Virginia Libraries</a>.</p>
<p>This notebook is adapted by Zhuo Chen under <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons CC BY License</a>.</p>
<p>For questions/comments/improvements, email <a class="reference external" href="mailto:zhuo&#46;chen&#37;&#52;&#48;ithaka&#46;org">zhuo<span>&#46;</span>chen<span>&#64;</span>ithaka<span>&#46;</span>org</a> or <a class="reference external" href="mailto:nathan&#46;kelber&#37;&#52;&#48;ithaka&#46;org">nathan<span>&#46;</span>kelber<span>&#64;</span>ithaka<span>&#46;</span>org</a>.<br /></p>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="multilingual-ner-3">
<h1>Multilingual NER 3<a class="headerlink" href="#multilingual-ner-3" title="Link to this heading">#</a></h1>
<p>This is lesson 3 in the educational series on named entity recognition.</p>
<p><strong>Description:</strong> This notebook describes:</p>
<ul class="simple">
<li><p>how to understand word embeddings as a concept</p></li>
<li><p>how to understand Machine Learning as a concept</p></li>
<li><p>how to understand supervised learning</p></li>
<li><p>how to do NER ML in spaCy 3</p></li>
</ul>
<p><strong>Use case:</strong> Explanation</p>
<p><strong>Difficulty:</strong> Intermediate</p>
<p><strong>Completion time:</strong> 75 minutes</p>
<p><strong>Knowledge Required:</strong></p>
<ul class="simple">
<li><p>Python basics (<a class="reference internal" href="../Python/basic/python-basics-1.html"><span class="std std-doc">start learning Python basics</span></a>)</p></li>
<li><p><a class="reference internal" href="../Python/intermediate/python-intermediate-4.html"><span class="std std-doc">Python intermediate 4</span></a> (OOP, classes, instances, inheritance)</p></li>
</ul>
<p><strong>Knowledge Recommended:</strong></p>
<ul class="simple">
<li><p>Basic file operations (<a class="reference internal" href="../Python/intermediate/python-intermediate-2.html"><span class="std std-doc">start learning file operations</span></a>)</p></li>
<li><p>Data cleaning with <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> (<a class="reference internal" href="../Python/pandas/pandas-1.html"><span class="std std-doc">start learning Pandas</span></a>)</p></li>
</ul>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="install-libraries">
<h1>Install libraries<a class="headerlink" href="#install-libraries" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>spacy<span class="w"> </span>#<span class="w"> </span><span class="k">for</span><span class="w"> </span>NLP
<span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>pandas<span class="w"> </span>#<span class="w"> </span><span class="k">for</span><span class="w"> </span>making<span class="w"> </span>tabular<span class="w"> </span>data
<span class="o">!</span>python3<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>download<span class="w"> </span>en_core_web_sm<span class="w"> </span>#<span class="w"> </span><span class="k">for</span><span class="w"> </span>English<span class="w"> </span>NER
<span class="o">!</span>python3<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>download<span class="w"> </span>en_core_web_md<span class="w"> </span>#<span class="w"> </span><span class="k">for</span><span class="w"> </span>showing<span class="w"> </span>the<span class="w"> </span>word<span class="w"> </span>vectors
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction-to-word-embeddings">
<h1>Introduction to word embeddings<a class="headerlink" href="#introduction-to-word-embeddings" title="Link to this heading">#</a></h1>
<p>How do we represent word meanings in NLP? One way we can represent word meanings is to use word vectors. <strong>Word embeddings</strong> are vector representations of words.</p>
<section id="distributional-hypothesis">
<h2>Distributional hypothesis<a class="headerlink" href="#distributional-hypothesis" title="Link to this heading">#</a></h2>
<p>Word embeddings is inspired by the <strong>distributional hypothesis</strong> proposed by Harris (<a class="reference external" href="https://doi.org/10.1080/00437956.1954.11659520">1954</a>). This theory could be summarized as: words that have similar context will have similar meanings.</p>
<p>What does “context” mean in word embeddings? Basically, “context” means the neighboring words of a target word.</p>
<p>Consider the following example. If we choose “village” as the target word and choose a fixed size context window of 2, the two words before “village” and the two words after “village” will constitute the context of the target word.</p>
<p>Treblinka is <strong>a small</strong> <strong><span style="color: blue;">village</span></strong> <strong>in Poland.</strong></p>
</section>
<section id="word2vec">
<h2>Word2Vec<a class="headerlink" href="#word2vec" title="Link to this heading">#</a></h2>
<p>Google’s pre-trained word2vec model includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features, which means each of the 3 million words in the vocabulary is represented by a vector with 300 floating numbers. Word2Vec is one of the most popular techniques to learn word embeddings.</p>
<p>The training samples are the (target, context) pairs from the text data. For example, suppose your source text is the sentence “The quick brown fox jumps over the lazy dog”. If you choose “quick” as your target word and have set a context window of size 2, you will get three training samples for it, i.e. (quick, the), (quick, brown) and (quick fox).</p>
<p><strong>McCormick, C</strong>. (2016, April 19). Word2Vec Tutorial - The Skip-Gram Model. Retrieved from <a class="reference external" href="http://mccormickml.com/">http://mccormickml.com/</a></p>
<p>The word2vec model is trained to accomplish the following task: given the input word <span class="math notranslate nohighlight">\(w_{1}\)</span>, for each word <span class="math notranslate nohighlight">\(w_{2}\)</span> in our vocab, how likely <span class="math notranslate nohighlight">\(w_{2}\)</span> is a context word of <span class="math notranslate nohighlight">\(w_{1}\)</span>.</p>
<p>The network is going to learn the statistics from the number of times each (target, context) shows up. So, for example, if you have a text about kings, queens and kingdoms, the network is probably going to get many more training samples of (“King”, “Queen”) than (“King”, “kangaroo”). Therefore, if you give your trained model the word “King” as input, then it will output a much higher probability for “Queen” than it will for “kangaroo”.</p>
</section>
<section id="word-vectors-in-spacy">
<h2>Word vectors in SpaCy<a class="headerlink" href="#word-vectors-in-spacy" title="Link to this heading">#</a></h2>
<p>We have used the small English model from spaCy in the previous two notebooks. Actually, there are medium size and large size English models from spaCy as well. Both are trained using the word2vec family of algorithms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>

<span class="c1"># Load the medium size English model from spaCy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;en_core_web_md&#39;</span><span class="p">)</span>

<span class="c1"># Get the word vector for the word &quot;King&quot;</span>
<span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;King&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">vector</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the size of the vector</span>
<span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;King&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">vector</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the similarity between the two words &quot;King&quot; and &quot;Queen&quot;</span>
<span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;King&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;Queen&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the similarity between the two words &quot;King&quot; and &quot;kangaroo&quot;</span>
<span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;King&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;kangaroo&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction-to-machine-learning">
<h1>Introduction to Machine Learning<a class="headerlink" href="#introduction-to-machine-learning" title="Link to this heading">#</a></h1>
<p>How is word2vector model trained? The model is trained using a machine learning technique.</p>
<p>Machine learning is a branch of artificial intelligence. Traditionally the human writes the rules in a computer system to perform a specific task. In machine learning, we use statistics to write the rules for us.</p>
<section id="the-machine-learning-pipeline">
<h2>The machine learning pipeline<a class="headerlink" href="#the-machine-learning-pipeline" title="Link to this heading">#</a></h2>
<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_ML_pipeline.png' width=700></center>
<p>Let’s use a simple example to understand the ML pipeline. Suppose you are interested in the relationship between the size and the price of a house in your neighborhood. Specifically, you would like to use the size of a house to predict its price. You go to Redfin/Zillow and find the information about the recently sold houses in your neighborhood. You note down their size and sale price. You draw a scatter plot like the following to examine the data.</p>
<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_housebuying_scatter.png' width=300></center>
<p>What you have in this scatter plot is your data. Now, you would like to derive a relationship between the house size and house price. Let’s use linear regression in this case. Essentially, you fit a line to the data points.</p>
<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_housebuying.png' width=300></center>
<p>The function for this line is y = ax + b (where y is the price and x is the # of sqft). Of course, you would not just fit any line to your data points. You would want to fit a line so that the difference between the actual house prices and the predicted house prices is the smallest. Our task, then, reduces to the calculation of the value of a and b in the function y = ax + b so that the difference between the actual house prices and the predicted house prices is the smallest.</p>
</section>
<section id="ml-in-word2vec">
<h2>ML in Word2Vec<a class="headerlink" href="#ml-in-word2vec" title="Link to this heading">#</a></h2>
<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_ML_pipeline.png' width=700></center>
<p>The ML method used in word2vec is a shallow neural network with one hidden layer of neurons and one output layer of neurons. Chris McCormick has a very detailed explanation of this model in his blog post <a class="reference external" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</a>. Let’s go take a look.</p>
</section>
<section id="supervised-learning">
<h2>Supervised Learning<a class="headerlink" href="#supervised-learning" title="Link to this heading">#</a></h2>
<p><strong>Supervised learning</strong> is the process by which a system learns from a set of inputs that have known labels. To train a model, you first need training data – text examples, and the gold standard – labels you want the model to predict. This means that your training data need to be annotated.</p>
<section id="training-and-evaluation">
<h3>Training and evaluation<a class="headerlink" href="#training-and-evaluation" title="Link to this heading">#</a></h3>
<p>“When training a model, we don’t just want it to memorize our examples – we want it to come up with a theory that can be generalized across unseen data. After all, we don’t just want the model to learn that this one instance of “Amazon” right here is a company – we want it to learn that “Amazon”, in contexts like this, is most likely a company. That’s why the training data should always be representative of the data we want to process. A model trained on Wikipedia, where sentences in the first person are extremely rare, will likely perform badly on Twitter. Similarly, a model trained on romantic novels will likely perform badly on legal text.</p>
<p>This also means that in order to know how the model is performing, and whether it’s learning the right things, you don’t only need training data – you’ll also need evaluation data.”</p>
<p><a class="reference external" href="https://spacy.io/usage/training">https://spacy.io/usage/training</a></p>
<p><strong>Honnibal, M., &amp; Montani, I.</strong> (2017). spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.</p>
<p>The training data is used to hone a statistical model via predetermined algorithms. It does this by making guesses about what the proper labels are. It then checks its accuracy against the correct labels, i.e., the annotated labels, and makes adjustments accordingly. Once it is finished viewing and guessing across all the training data, the first <strong>epoch</strong>, or <strong>iteration</strong> over the data, is finished. At this stage, the model then tests its accuracy against the evaluation data. The training data is then randomized and given back to the system for x number of epochs.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ner-with-entityruler-vs-ml-ner">
<h1>NER with EntityRuler vs. ML NER<a class="headerlink" href="#ner-with-entityruler-vs-ml-ner" title="Link to this heading">#</a></h1>
<p>In this section, we are going to make two models to do the same NER task, one doing NER with an EntityRuler and the other doing NER using word vectors.</p>
<p>First, let’s download the two data files needed for this example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">urllib.request</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Check if a data folder exists. If not, create it.</span>
<span class="n">data_folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;../data/&#39;</span><span class="p">)</span>
<span class="n">data_folder</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Download the files</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_HarryPotter_FilmSpells.csv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_HarryPotter_Spells.csv&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s1">&#39;../data/&#39;</span> <span class="o">+</span> <span class="n">url</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>   
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample files ready.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first file stores the information about the spells in Harry Potter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="n">spells_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/NER_HarryPotter_Spells.csv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;;&quot;</span><span class="p">)</span>
<span class="n">spells_df</span>
</pre></div>
</div>
</div>
</div>
<p>In the second file, we find the characters speaking and their speech. Notice that there is a column storing the spells found in the sentence if there is one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">film_spells</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/NER_HarryPotter_FilmSpells.csv&#39;</span><span class="p">)</span>
<span class="n">film_spells</span>
</pre></div>
</div>
</div>
</div>
<p>Suppose we would like to create a model that can identify spells in a sentence and give it the label ‘SPELL’.</p>
<section id="create-an-nlp-model-with-an-entityruler-to-identify-the-spells">
<h2>Create an NLP model with an EntityRuler to identify the spells<a class="headerlink" href="#create-an-nlp-model-with-an-entityruler-to-identify-the-spells" title="Link to this heading">#</a></h2>
<p>In the following, we will first create a NLP model with an entity ruler that identifies spells. This section can be seen as a review of what we have learned about EntityRuler in Wednesday’s lesson.
Before we create a new EntityRuler, we will do some preprocessing of the data to get the patterns that we will add to the EntityRuler.</p>
<section id="preprocessing-the-data">
<h3>Preprocessing the data<a class="headerlink" href="#preprocessing-the-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fill the NaN cells with an empty string</span>
<span class="n">spells_df</span><span class="p">[</span><span class="s1">&#39;Incantation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spells_df</span><span class="p">[</span><span class="s1">&#39;Incantation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Get all spells</span>
<span class="n">spells</span> <span class="o">=</span> <span class="n">spells_df</span><span class="p">[</span><span class="s1">&#39;Incantation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># Put all strs in the &#39;Incantation&#39; column in a list</span>
<span class="n">spells</span> <span class="o">=</span> <span class="p">[</span><span class="n">spell</span> <span class="k">for</span> <span class="n">spell</span> <span class="ow">in</span> <span class="n">spells</span> <span class="k">if</span> <span class="n">spell</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="c1"># Get all non-empty strs from the list, i.e. all the spells</span>

<span class="c1"># Take a look at the spells</span>
<span class="n">spells</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-the-patterns-to-be-added-to-the-entityruler">
<h3>Creating the patterns to be added to the EntityRuler<a class="headerlink" href="#creating-the-patterns-to-be-added-to-the-entityruler" title="Link to this heading">#</a></h3>
<p>Recall from Wednesday’s lesson that the patterns we add to an EntityRuler look like the following.</p>
<p><code class="docutils literal notranslate"><span class="pre">patterns</span> <span class="pre">=</span> <span class="pre">[{&quot;label&quot;:</span> <span class="pre">&quot;GPE&quot;,</span> <span class="pre">&quot;pattern&quot;:</span> <span class="pre">&quot;Aars&quot;}]</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write the pattern to be added to the ruler</span>
<span class="n">patterns</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span><span class="s2">&quot;SPELL&quot;</span><span class="p">,</span> <span class="s2">&quot;pattern&quot;</span><span class="p">:</span><span class="n">spell</span><span class="p">}</span> <span class="k">for</span> <span class="n">spell</span> <span class="ow">in</span> <span class="n">spells</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have the patterns ready, we can add them to an EntityRuler and add the ruler as a new pipe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an EntityRuler and add the patterns to the ruler</span>
<span class="n">entruler_nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">blank</span><span class="p">(</span><span class="s1">&#39;en&#39;</span><span class="p">)</span> <span class="c1"># Create a blank English model</span>
<span class="n">ruler</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;entity_ruler&quot;</span><span class="p">)</span> 
<span class="n">ruler</span><span class="o">.</span><span class="n">add_patterns</span><span class="p">(</span><span class="n">patterns</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Ron Weasley: Wingardium Leviosa! Hermione Granger: You&#39;re saying it wrong. </span>
<span class="s2">It&#39;s Wing-gar-dium Levi-o-sa, make the &#39;gar&#39; nice and long. </span>
<span class="s2">Ron Weasley: You do it, then, if you&#39;re so clever&quot;&quot;&quot;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EntRulerModel&#39;</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this model, we have basically hard written all spell strings in the EntityRuler.</p>
</section>
</section>
<section id="train-a-nlp-model-using-ml-to-identify-the-spells">
<h2>Train a NLP model using ML to identify the spells<a class="headerlink" href="#train-a-nlp-model-using-ml-to-identify-the-spells" title="Link to this heading">#</a></h2>
<p>The format of the training data will look like the following. It is a list of tuples. In each tuple, the first element is the text string containing spells and the second element is a dictionary. The key of the dictionary is ‘entities’. The value is a list of lists. In each list, we find the starting index, ending index and the label of the spell(s) found in the text string.</p>
<p><code class="docutils literal notranslate"><span class="pre">[</span> <span class="pre">('Oculus</span> <span class="pre">Reparo',</span> <span class="pre">{'entities':</span> <span class="pre">[[0,</span> <span class="pre">13,</span> <span class="pre">'SPELL']]}),</span> <span class="pre">('Alohomora',</span> <span class="pre">{'entities':</span> <span class="pre">[[0,</span> <span class="pre">9,</span> <span class="pre">'SPELL']]})</span> <span class="pre">]</span></code></p>
<p>The text strings we use for the training are from the ‘Sentence’ column of the film_spells dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Take a look at the film_spells df</span>
<span class="n">film_spells</span>
</pre></div>
</div>
</div>
</div>
<p>Since we have hard written all spell strings in the EntityRuler and give them the label ‘SPELL’, we could just use this model to generate labeled data as our training data and evaluation data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span> <span class="c1"># for sentence tokenization</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_labeled_data</span><span class="p">(</span><span class="n">ls_sents</span><span class="p">):</span> <span class="c1"># the input will be a list of strings</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ls_sents</span><span class="p">)</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">labeled_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">:</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="c1"># create a doc object</span>
        <span class="k">if</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span> <span class="o">!=</span> <span class="p">():</span> <span class="c1"># if there is at least one entity identified</span>
            <span class="n">labeled_data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sent</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;entities&quot;</span><span class="p">:[[</span><span class="n">ent</span><span class="o">.</span><span class="n">start_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">end_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">]</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">]}))</span>
    <span class="k">return</span> <span class="n">labeled_data</span>       

<span class="c1"># Assign the result from the function to a new variable</span>
<span class="n">training_validation_data</span> <span class="o">=</span> <span class="n">generate_labeled_data</span><span class="p">(</span><span class="n">film_spells</span><span class="p">[</span><span class="s1">&#39;Sentence&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

<span class="c1"># Take a look at the labeled data</span>
<span class="n">training_validation_data</span>
</pre></div>
</div>
</div>
</div>
<p>spaCy 3 requires that our data be stored in the proprietary <code class="docutils literal notranslate"><span class="pre">.spacy</span></code> format. To do that we need to use the <code class="docutils literal notranslate"><span class="pre">DocBin</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spacy.tokens</span><span class="w"> </span><span class="kn">import</span> <span class="n">DocBin</span> 

<span class="n">db</span> <span class="o">=</span> <span class="n">DocBin</span><span class="p">()</span> 

<span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">annot</span> <span class="ow">in</span> <span class="n">training_validation_data</span><span class="p">[:</span><span class="mi">19</span><span class="o">*</span><span class="mi">2</span><span class="p">]:</span> <span class="c1"># Get the first 38 tuples as the training data</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="c1"># create a doc object</span>
    <span class="n">doc</span><span class="o">.</span><span class="n">ents</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">char_span</span><span class="p">(</span><span class="n">ent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">ent</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">annot</span><span class="p">[</span><span class="s1">&#39;entities&#39;</span><span class="p">]]</span>
    <span class="n">db</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="n">db</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./train_spells.spacy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">annot</span> <span class="ow">in</span> <span class="n">training_validation_data</span><span class="p">[</span><span class="mi">19</span><span class="o">*</span><span class="mi">2</span><span class="p">:]:</span> <span class="c1"># Get the rest tuples as the validation data</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> 
    <span class="n">doc</span><span class="o">.</span><span class="n">ents</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="o">.</span><span class="n">char_span</span><span class="p">(</span><span class="n">ent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">ent</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">annot</span><span class="p">[</span><span class="s1">&#39;entities&#39;</span><span class="p">]]</span>
    <span class="n">db</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="n">db</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./valid_spells.spacy&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can finally start training our model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python3<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>init<span class="w"> </span>config<span class="w"> </span>--lang<span class="w"> </span>en<span class="w"> </span>--pipeline<span class="w"> </span>ner<span class="w"> </span>config.cfg<span class="w"> </span>--force
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python3<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>train<span class="w"> </span>config.cfg<span class="w"> </span>--output<span class="w"> </span>./output/spells-model/<span class="w"> </span>--paths.train<span class="w"> </span>./train_spells.spacy<span class="w"> </span>--paths.dev<span class="w"> </span>./valid_spells.spacy
</pre></div>
</div>
</div>
</div>
<p>Now let’s finally run our model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the best model</span>
<span class="n">model_best</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./output/spells-model/model-best&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s try our model on this long text string</span>
<span class="n">test_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;53. Imperio - Makes target obey every command But only for really, really funny pranks. 52. Piertotum Locomotor - Animates statues On one hand, this is awesome. On the other, someone would use this to scare me.</span>

<span class="s2">51. Aparecium - Make invisible ink appear</span>

<span class="s2">Your notes will be so much cooler.</span>

<span class="s2">50. Defodio - Carves through stone and steel</span>

<span class="s2">Sometimes you need to get the eff out of there.</span>

<span class="s2">49. Descendo - Moves objects downward</span>

<span class="s2">You&#39;ll never have to get a chair to reach for stuff again.</span>

<span class="s2">48. Specialis Revelio - Reveals hidden magical properties in an object</span>

<span class="s2">I want to know what I&#39;m eating and if it&#39;s magical.</span>

<span class="s2">47. Meteolojinx Recanto - Ends effects of weather spells</span>

<span class="s2">Otherwise, someone could make it sleet in your bedroom forever.</span>

<span class="s2">46. Cave Inimicum/Protego Totalum - Strengthens an area&#39;s defenses</span>

<span class="s2">Helpful, but why are people trying to break into your campsite?</span>

<span class="s2">45. Impedimenta - Freezes someone advancing toward you</span>

<span class="s2">&quot;Stop running at me! But also, why are you running at me?&quot;</span>

<span class="s2">44. Obscuro - Blindfolds target</span>

<span class="s2">Finally, we don&#39;t have to rely on &quot;No peeking.&quot;</span>

<span class="s2">43. Reducto - Explodes object</span>

<span class="s2">The &quot;raddest&quot; of all spells.</span>

<span class="s2">42. Anapneo - Clears someone&#39;s airway</span>

<span class="s2">This could save a life, but hopefully you won&#39;t need it.</span>

<span class="s2">41. Locomotor Mortis - Leg-lock curse</span>

<span class="s2">Good for footraces and Southwest Airlines flights.</span>

<span class="s2">40. Geminio - Creates temporary, worthless duplicate of any object</span>

<span class="s2">You could finally live your dream of lying on a bed of marshmallows, and you&#39;d only need one to start.</span>

<span class="s2">39. Aguamenti - Shoot water from wand</span>

<span class="s2">No need to replace that fire extinguisher you never bought.</span>

<span class="s2">38. Avada Kedavra - The Killing Curse</span>

<span class="s2">One word: bugs.</span>

<span class="s2">37. Repelo Muggletum - Repels Muggles</span>

<span class="s2">Sounds elitist, but seriously, Muggles ruin everything. Take it from me, a Muggle.</span>

<span class="s2">36. Stupefy - Stuns target</span>

<span class="s2">Since this is every other word of the &quot;Deathly Hallows&quot; script, I think it&#39;s pretty useful.&quot;&quot;&quot;</span>

<span class="c1"># Create a doc object out of the text string using the trained model</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">model_best</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span>

<span class="c1"># Find out the entities</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s also try the model we created with an EntityRuler with all spell names hard written in it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a doc object out of the text string using the EntityRuler model</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">entruler_nlp</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span>

<span class="c1"># Find out the entities</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It seems in this example our EntityRuler model performs better than our trained model. Why do we think that is?</p>
<p>Part of the reason we aren’t getting better results is something that Ines Montani describes in this Stack Overflow answer <a class="reference external" href="https://stackoverflow.com/questions/50580262/how-to-use-spacy-to-create-a-new-entity-and-learn-only-from-keyword-list/50603247#50603247">https://stackoverflow.com/questions/50580262/how-to-use-spacy-to-create-a-new-entity-and-learn-only-from-keyword-list/50603247#50603247</a></p>
<p>“The advantage of training the named entity recognizer to detect SPECIES in your text is that the model won’t only be able to recognise your examples, but also generalise and recognise other species in context. If you only want to find a fixed set of terms and not more, a simpler, rule-based approach might work better for you.”</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="references">
<h1>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h1>
<p>McCormick, C. (2016, April 19). Word2Vec Tutorial - The Skip-Gram Model. Retrieved from <a class="reference external" href="http://www.mccormickml.com">http://www.mccormickml.com</a></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./src/TextMining"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Multilingual NER 3</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#install-libraries">Install libraries</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-word-embeddings">Introduction to word embeddings</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distributional-hypothesis">Distributional hypothesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec">Word2Vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-vectors-in-spacy">Word vectors in SpaCy</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-machine-learning">Introduction to Machine Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-machine-learning-pipeline">The machine learning pipeline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-in-word2vec">ML in Word2Vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-learning">Supervised Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-evaluation">Training and evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#ner-with-entityruler-vs-ml-ner">NER with EntityRuler vs. ML NER</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-an-nlp-model-with-an-entityruler-to-identify-the-spells">Create an NLP model with an EntityRuler to identify the spells</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-the-data">Preprocessing the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-the-patterns-to-be-added-to-the-entityruler">Creating the patterns to be added to the EntityRuler</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-nlp-model-using-ml-to-identify-the-spells">Train a NLP model using ML to identify the spells</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By University of South Carolina Libraries
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>