{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "This notebook was created by [William Mattingly](https://datascience.si.edu/people/dr-william-mattingly) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/) and [Zoe LeBlanc](https://ischool.illinois.edu/people/zoe-leblanc) for the 2021 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Virginia Libraries](https://library.virginia.edu).\n",
    "\n",
    "This notebook is adapted by Zhuo Chen under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "For questions/comments/improvements, email zhuo.chen@ithaka.org or nathan.kelber@ithaka.org.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# Multilingual NER 3\n",
    "\n",
    "This is lesson 3 in the educational series on named entity recognition. \n",
    "\n",
    "**Description:** This notebook describes:\n",
    "* how to understand word embeddings as a concept\n",
    "* how to understand Machine Learning as a concept\n",
    "* how to understand supervised learning\n",
    "* how to do NER ML in spaCy 3\n",
    "\n",
    "**Use case:** Explanation\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Completion time:** 75 minutes\n",
    "\n",
    "**Knowledge Required:** \n",
    "\n",
    "* Python basics ([start learning Python basics](../../PythonForDataAnalysis/GettingStarted/basic/python-basics-1.ipynb))\n",
    "* [Python intermediate 4](../../PythonForDataAnalysis/GettingStarted/intermediate/python-intermediate-4.ipynb) (OOP, classes, instances, inheritance)\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "\n",
    "* Basic file operations ([start learning file operations](../../PythonForDataAnalysis/GettingStarted/intermediate/python-intermediate-2.ipynb))\n",
    "* Data cleaning with `Pandas` ([start learning Pandas](../../PythonForDataAnalysis/GettingStarted/pandas/pandas-1.ipynb))\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26823dcc",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b94b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (78.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mearacox/opt/anaconda3/envs/spacy-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy # for NLP\n",
    "%pip install pandas # for making tabular data\n",
    "!python -m spacy download en_core_web_sm # for English NER\n",
    "!python -m spacy download en_core_web_md # for showing the word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac6c55",
   "metadata": {},
   "source": [
    "# Introduction to word embeddings\n",
    "\n",
    "How do we represent word meanings in NLP? One way we can represent word meanings is to use word vectors. **Word embeddings** are vector representations of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a2de3",
   "metadata": {},
   "source": [
    "## Distributional hypothesis\n",
    "\n",
    "Word embeddings is inspired by the **distributional hypothesis** proposed by Harris ([1954](https://doi.org/10.1080/00437956.1954.11659520)). This theory could be summarized as: words that have similar context will have similar meanings.\n",
    "\n",
    "What does \"context\" mean in word embeddings? Basically, \"context\" means the neighboring words of a target word. \n",
    "\n",
    "Consider the following example. If we choose \"village\" as the target word and choose a fixed size context window of 2, the two words before \"village\" and the two words after \"village\" will constitute the context of the target word.\n",
    "\n",
    "Treblinka is **a small** **<span style=\"color: blue;\">village</span>** **in Poland.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39b123",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Google’s pre-trained word2vec model includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features, which means each of the 3 million words in the vocabulary is represented by a vector with 300 floating numbers. Word2Vec is one of the most popular techniques to learn word embeddings.\n",
    "\n",
    "The training samples are the (target, context) pairs from the text data. For example, suppose your source text is the sentence \"The quick brown fox jumps over the lazy dog\". If you choose \"quick\" as your target word and have set a context window of size 2, you will get three training samples for it, i.e. (quick, the), (quick, brown) and (quick fox).   \n",
    "\n",
    "**McCormick, C**. (2016, April 19). Word2Vec Tutorial - The Skip-Gram Model. Retrieved from http://mccormickml.com/\n",
    "\n",
    "The word2vec model is trained to accomplish the following task: given the input word $w_{1}$, for each word $w_{2}$ in our vocab, how likely $w_{2}$ is a context word of $w_{1}$.\n",
    "\n",
    "The network is going to learn the statistics from the number of times each (target, context) shows up. So, for example, if you have a text about kings, queens and kingdoms, the network is probably going to get many more training samples of (\"King\", \"Queen\") than (\"King\", \"kangaroo\"). Therefore, if you give your trained model the word \"King\" as input, then it will output a much higher probability for \"Queen\" than it will for \"kangaroo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ae805",
   "metadata": {},
   "source": [
    "## Word vectors in SpaCy\n",
    "\n",
    "We have used the small English model from spaCy in the previous two notebooks. Actually, there are medium size and large size English models from spaCy as well. Both are trained using the word2vec family of algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663703eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.0644e-01, -5.1205e-01,  6.4921e-03, -2.9194e-01, -5.6515e-01,\n",
       "       -1.1523e-01,  7.7274e-02,  3.3561e-01,  1.1593e-01,  2.3516e+00,\n",
       "        5.1773e-02, -5.4229e-01, -5.7972e-01,  1.3220e-01,  2.8430e-01,\n",
       "       -7.9592e-02, -2.6762e-01,  1.8301e-01, -4.1264e-01,  2.0459e-01,\n",
       "        1.4436e-01, -1.8714e-01, -3.1393e-01,  1.7821e-01, -1.0997e-01,\n",
       "       -2.5584e-01, -1.1149e-01,  9.6212e-02, -1.6168e-01,  4.0055e-01,\n",
       "       -2.6115e-01,  5.3777e-01, -5.2382e-01,  2.7637e-01,  7.2191e-01,\n",
       "        6.0405e-02, -1.7922e-01,  1.8020e-01, -1.4381e-01, -1.4795e-01,\n",
       "       -8.1394e-02,  5.8282e-02,  2.2964e-02, -2.6374e-01,  1.0704e-01,\n",
       "       -4.5425e-01, -1.9964e-01,  3.7720e-01, -9.7784e-02, -3.1999e-01,\n",
       "       -7.8509e-02,  6.1502e-01,  7.1643e-02, -3.0930e-02,  2.1508e-01,\n",
       "        2.5280e-01, -3.1643e-01,  6.6698e-01,  1.9813e-02, -3.2311e-01,\n",
       "        2.9266e-02, -4.1403e-02,  2.8346e-01, -7.9143e-01,  1.3327e-01,\n",
       "        7.7231e-02, -1.8724e-01, -3.3146e-01, -2.0797e-01, -6.9326e-01,\n",
       "       -2.3412e-01, -6.8752e-02,  3.8252e-02, -3.2459e-01, -8.3609e-03,\n",
       "        1.2945e-01, -2.8316e-01, -5.7546e-01,  2.4336e-01,  5.6433e-01,\n",
       "       -7.1285e-01, -5.4738e-03, -2.3305e-01, -7.1578e-02,  4.8301e-01,\n",
       "       -3.4312e-01,  2.7365e-01, -1.1771e+00, -6.5800e-01, -1.9009e-01,\n",
       "        7.4287e-03,  3.2977e-01, -1.6647e-01,  2.6851e-01,  1.1811e-01,\n",
       "       -6.2440e-02, -4.9987e-02,  7.1011e-04, -5.6201e-02, -2.6696e-01,\n",
       "        3.1351e-01,  4.3955e-01, -8.8727e-02, -1.2315e-01,  1.8855e-01,\n",
       "       -1.0834e+00, -3.3041e-01,  5.7325e-01, -3.9947e-01,  1.4852e-02,\n",
       "       -3.6787e-01,  3.7842e-01, -2.8962e-01, -7.0543e-02, -5.8699e-02,\n",
       "        5.3076e-01, -1.2736e-01, -3.5724e-01, -1.5007e-01,  1.3823e-02,\n",
       "       -1.9497e-01, -3.7189e-01,  2.6255e-01, -7.6826e-02,  8.4217e-02,\n",
       "       -5.3640e-01,  1.7393e-01, -1.4698e-01, -1.1068e-01,  1.7709e-01,\n",
       "       -3.9556e-01,  1.0433e-01,  9.2675e-03, -1.2282e-01, -3.9842e-01,\n",
       "       -2.7758e-01, -6.9369e-01,  7.0128e-02,  8.2794e-02,  4.8342e-02,\n",
       "       -2.7038e+00, -1.6812e-01,  3.1413e-01,  2.4313e-02, -3.6423e-02,\n",
       "        1.9292e-01,  4.4872e-01, -4.5427e-01, -3.7271e-01, -9.9532e-01,\n",
       "       -1.3411e-01, -6.0312e-01,  1.6642e-01, -2.4611e-02,  6.6891e-01,\n",
       "        6.3476e-02, -1.1327e+00, -3.3786e-01, -1.2576e-02,  3.5344e-01,\n",
       "        2.6643e-01, -1.9404e-01, -1.9516e-01,  6.3670e-01,  2.1373e-01,\n",
       "       -2.8936e-01, -6.8847e-02, -1.9738e-01, -3.5305e-01,  1.0219e-01,\n",
       "        1.1744e-01,  3.7159e-02,  4.1041e-01, -1.3766e-02, -1.0325e-02,\n",
       "        1.0461e-02,  3.0697e-02, -3.3016e-01,  2.4668e-01, -2.6058e-01,\n",
       "        2.8665e-01, -7.8507e-02,  6.8945e-03,  1.0980e-01, -6.4179e-01,\n",
       "        2.4617e-03, -2.4693e-01, -1.1188e-02,  3.0838e-01,  4.5557e-01,\n",
       "       -6.2189e-01,  1.4873e-01,  3.5440e-01,  2.8642e-01, -2.4211e-01,\n",
       "       -1.2404e-01,  2.3326e-01,  1.9555e-01, -1.2425e-02,  1.9920e-01,\n",
       "       -1.7935e-01,  5.2031e-01, -4.3666e-01,  8.6211e-02,  1.7282e-01,\n",
       "        6.5266e-02,  2.8701e-01,  6.0238e-01,  3.1843e-01, -4.7646e-01,\n",
       "       -2.1181e-02, -2.7726e-01,  4.0253e-01,  3.9968e-01,  1.8580e-02,\n",
       "       -6.2663e-01,  3.4149e-01,  4.4687e-01, -4.6135e-01,  4.4174e-01,\n",
       "       -5.7541e-02, -1.9038e-02, -2.2626e-01,  5.8452e-02, -4.6681e-02,\n",
       "       -5.3295e-03, -1.8257e-03,  4.8565e-01, -4.6144e-01, -4.5877e-01,\n",
       "       -1.5891e-01,  1.3037e-01, -2.9183e-01,  6.9206e-02, -4.9825e-02,\n",
       "        5.5077e-01,  1.4730e-01, -1.9255e-01, -2.3916e-01, -1.9319e-01,\n",
       "        1.5643e-01,  3.3491e-01, -3.1913e-01,  2.0674e-01,  6.4556e-02,\n",
       "       -2.3195e-01,  1.2657e-01, -2.5131e-03,  1.1079e-01,  3.0436e-01,\n",
       "        6.9529e-02,  1.1027e-01,  2.6285e-01, -2.3103e-01, -2.8933e-01,\n",
       "       -5.0675e-02, -8.9796e-02,  2.5816e-01, -8.0917e-02,  3.3160e-01,\n",
       "       -3.5930e-01,  2.8336e-01,  1.4145e-01,  2.9012e-01,  1.5677e-01,\n",
       "        1.3225e-01, -5.0090e-01,  2.2110e-01,  6.9609e-01, -9.6917e-02,\n",
       "       -2.4966e-02, -2.9391e-01, -3.1240e-01, -3.8031e-01, -2.0604e-01,\n",
       "        1.5959e-01, -5.6155e-01,  2.9170e-01, -5.0459e-01,  6.5684e-02,\n",
       "        5.8594e-01,  1.3003e-02,  6.5874e-01, -4.7811e-01,  2.8794e-01,\n",
       "        3.5918e-01,  4.3347e-01, -4.2480e-01,  3.5892e-01, -6.0925e-01,\n",
       "       -7.1236e-01,  2.9490e-01, -2.1479e-01,  2.5658e-01, -1.9358e-01,\n",
       "        1.1057e+00,  2.2862e-01,  2.1859e-01, -1.9044e-01, -1.0253e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the medium size English model from spaCy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Get the word vector for the word \"King\"\n",
    "nlp(\"King\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0423175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the vector\n",
    "nlp(\"King\").vector.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa846c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38253095746040344"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the similarity between the two words \"King\" and \"Queen\"\n",
    "nlp(\"King\").similarity(nlp(\"Queen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2dfe53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2849182188510895"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the similarity between the two words \"King\" and \"kangaroo\"\n",
    "nlp(\"King\").similarity(nlp(\"kangaroo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99377411-f756-4003-994d-6a202c51cf6e",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning \n",
    "\n",
    "How is word2vector model trained? The model is trained using a machine learning technique. \n",
    "\n",
    "Machine learning is a branch of artificial intelligence. Traditionally the human writes the rules in a computer system to perform a specific task. In machine learning, we use statistics to write the rules for us.\n",
    "\n",
    "## The machine learning pipeline\n",
    "<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_ML_pipeline.png' width=700></center>\n",
    "\n",
    "Let's use a simple example to understand the ML pipeline. Suppose you are interested in the relationship between the size and the price of a house in your neighborhood. Specifically, you would like to use the size of a house to predict its price. You go to Redfin/Zillow and find the information about the recently sold houses in your neighborhood. You note down their size and sale price. You draw a scatter plot like the following to examine the data. \n",
    "\n",
    "<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_housebuying_scatter.png' width=300></center>\n",
    "\n",
    "What you have in this scatter plot is your data. Now, you would like to derive a relationship between the house size and house price. Let's use linear regression in this case. Essentially, you fit a line to the data points. \n",
    "\n",
    "<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_housebuying.png' width=300></center>\n",
    "\n",
    "The function for this line is y = ax + b (where y is the price and x is the # of sqft). Of course, you would not just fit any line to your data points. You would want to fit a line so that the difference between the actual house prices and the predicted house prices is the smallest. Our task, then, reduces to the calculation of the value of a and b in the function y = ax + b so that the difference between the actual house prices and the predicted house prices is the smallest.\n",
    "\n",
    "## ML in Word2Vec\n",
    "\n",
    "<center><img src='https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_ML_pipeline.png' width=700></center>\n",
    "\n",
    "The ML method used in word2vec is a shallow neural network with one hidden layer of neurons and one output layer of neurons. Chris McCormick has a very detailed explanation of this model in his blog post http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/. Let's go take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7bf26-6a6c-4cfb-9987-04ae0342da31",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41c009-2809-4dc1-8939-dbf3951665df",
   "metadata": {},
   "source": [
    "**Supervised learning** is the process by which a system learns from a set of inputs that have known labels. To train a model, you first need training data – text examples, and the gold standard – labels you want the model to predict. This means that your training data need to be annotated.\n",
    "\n",
    "### Training and evaluation\n",
    "\n",
    "\"When training a model, we don’t just want it to memorize our examples – we want it to come up with a theory that can be generalized across unseen data. After all, we don’t just want the model to learn that this one instance of “Amazon” right here is a company – we want it to learn that “Amazon”, in contexts like this, is most likely a company. That’s why the training data should always be representative of the data we want to process. A model trained on Wikipedia, where sentences in the first person are extremely rare, will likely perform badly on Twitter. Similarly, a model trained on romantic novels will likely perform badly on legal text.\n",
    "\n",
    "This also means that in order to know how the model is performing, and whether it’s learning the right things, you don’t only need training data – you’ll also need evaluation data.\"\n",
    "\n",
    "https://spacy.io/usage/training\n",
    "\n",
    "**Honnibal, M., & Montani, I.** (2017). spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.\n",
    "\n",
    "The training data is used to hone a statistical model via predetermined algorithms. It does this by making guesses about what the proper labels are. It then checks its accuracy against the correct labels, i.e., the annotated labels, and makes adjustments accordingly. Once it is finished viewing and guessing across all the training data, the first **epoch**, or **iteration** over the data, is finished. At this stage, the model then tests its accuracy against the evaluation data. The training data is then randomized and given back to the system for x number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68af31-4703-4750-865a-818142566dd5",
   "metadata": {},
   "source": [
    "# NER with EntityRuler vs. ML NER\n",
    "\n",
    "In this section, we are going to make two models to do the same NER task, one doing NER with an EntityRuler and the other doing NER using word vectors.\n",
    "\n",
    "First, let's download the two data files needed for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83871c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files ready.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if a data folder exists. If not, create it.\n",
    "data_folder = Path('../data/')\n",
    "data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Download the files\n",
    "urls = [\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_HarryPotter_FilmSpells.csv',\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/NER_HarryPotter_Spells.csv',\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    urllib.request.urlretrieve(url, '../data/' + url.rsplit('/', 1)[-1])   \n",
    "print('Sample files ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ba8af",
   "metadata": {},
   "source": [
    "The first file stores the information about the spells in Harry Potter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18218bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Incantation</th>\n",
       "      <th>Type</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summoning Charm</td>\n",
       "      <td>Accio</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Summons an object</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age Line</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Prevents people above or below a certain age f...</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Water-Making Spell</td>\n",
       "      <td>Aguamenti</td>\n",
       "      <td>Charm, Conjuration</td>\n",
       "      <td>Conjures water</td>\n",
       "      <td>Icy blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Launch an object up into the air</td>\n",
       "      <td>Alarte Ascendare</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Rockets target upward</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albus Dumbledore's Forceful Spell</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Spell</td>\n",
       "      <td>Great Force</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Waddiwasi</td>\n",
       "      <td>Waddiwasi</td>\n",
       "      <td>Jinx</td>\n",
       "      <td>Propels wad at the target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Washing up spell</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Cleans dishes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Levitation Charm</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Makes objects fly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>White sparks</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Jet of white sparks</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Episkey</td>\n",
       "      <td>Episkey</td>\n",
       "      <td>Healing spell, Charm</td>\n",
       "      <td>Heals minor injuries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name         Incantation  \\\n",
       "0                      Summoning Charm               Accio   \n",
       "1                             Age Line             Unknown   \n",
       "2                   Water-Making Spell           Aguamenti   \n",
       "3     Launch an object up into the air    Alarte Ascendare   \n",
       "4    Albus Dumbledore's Forceful Spell             Unknown   \n",
       "..                                 ...                 ...   \n",
       "296                          Waddiwasi           Waddiwasi   \n",
       "297                   Washing up spell             Unknown   \n",
       "298                   Levitation Charm  Wingardium Leviosa   \n",
       "299                       White sparks             Unknown   \n",
       "300                            Episkey             Episkey   \n",
       "\n",
       "                     Type                                             Effect  \\\n",
       "0                   Charm                                  Summons an object   \n",
       "1                   Charm  Prevents people above or below a certain age f...   \n",
       "2      Charm, Conjuration                                     Conjures water   \n",
       "3                   Charm                              Rockets target upward   \n",
       "4                   Spell                                        Great Force   \n",
       "..                    ...                                                ...   \n",
       "296                  Jinx                          Propels wad at the target   \n",
       "297                 Charm                                      Cleans dishes   \n",
       "298                 Charm                                  Makes objects fly   \n",
       "299                 Charm                                Jet of white sparks   \n",
       "300  Healing spell, Charm                               Heals minor injuries   \n",
       "\n",
       "        Light  \n",
       "0         NaN  \n",
       "1        Blue  \n",
       "2    Icy blue  \n",
       "3         Red  \n",
       "4         NaN  \n",
       "..        ...  \n",
       "296       NaN  \n",
       "297       NaN  \n",
       "298       NaN  \n",
       "299     White  \n",
       "300       NaN  \n",
       "\n",
       "[301 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spells_df = pd.read_csv('../data/NER_HarryPotter_Spells.csv', sep=\";\")\n",
    "spells_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148d7d2",
   "metadata": {},
   "source": [
    "In the second file, we find the characters speaking and their speech. Notice that there is a column storing the spells found in the sentence if there is one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a00ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>identified_spells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I should've known that you would be here, Prof...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Are the rumors true, Albus?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I'm afraid so, professor.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>The good and the bad.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>How fast is it, Harry?</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>I solemnly swear that I am up to no good.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Mischief managed.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4928 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Character                                           Sentence  \\\n",
       "0     Dumbledore  I should've known that you would be here, Prof...   \n",
       "1     McGonagall                Good evening, Professor Dumbledore.   \n",
       "2     McGonagall                        Are the rumors true, Albus?   \n",
       "3     Dumbledore                          I'm afraid so, professor.   \n",
       "4     Dumbledore                              The good and the bad.   \n",
       "...          ...                                                ...   \n",
       "4923    HERMIONE                             How fast is it, Harry?   \n",
       "4924       HARRY                                             Lumos.   \n",
       "4925       HARRY          I solemnly swear that I am up to no good.   \n",
       "4926       HARRY                                  Mischief managed.   \n",
       "4927       HARRY                                               Nox.   \n",
       "\n",
       "     movie_number identified_spells  \n",
       "0          film 1               NaN  \n",
       "1          film 1               NaN  \n",
       "2          film 1               NaN  \n",
       "3          film 1               NaN  \n",
       "4          film 1               NaN  \n",
       "...           ...               ...  \n",
       "4923       film 3               NaN  \n",
       "4924       film 3             Lumos  \n",
       "4925       film 3               NaN  \n",
       "4926       film 3               NaN  \n",
       "4927       film 3               Nox  \n",
       "\n",
       "[4928 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_spells = pd.read_csv('../data/NER_HarryPotter_FilmSpells.csv')\n",
    "film_spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948edc5",
   "metadata": {},
   "source": [
    "Suppose we would like to create a model that can identify spells in a sentence and give it the label 'SPELL'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51643760",
   "metadata": {},
   "source": [
    "## Create an NLP model with an EntityRuler to identify the spells\n",
    "\n",
    "In the following, we will first create a NLP model with an entity ruler that identifies spells. This section can be seen as a review of what we have learned about EntityRuler in Wednesday's lesson.\n",
    "Before we create a new EntityRuler, we will do some preprocessing of the data to get the patterns that we will add to the EntityRuler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b30d9",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f555ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accio',\n",
       " 'Unknown',\n",
       " 'Aguamenti',\n",
       " 'Alarte Ascendare',\n",
       " 'Alohomora',\n",
       " 'Anapneo',\n",
       " 'Anteoculatia',\n",
       " 'Aparecium',\n",
       " 'Appare Vestigium',\n",
       " 'Aqua Eructo',\n",
       " 'Arania Exumai',\n",
       " 'Arresto Momentum',\n",
       " 'Ascendio',\n",
       " 'Avada Kedavra',\n",
       " 'Avifors\\xa0',\n",
       " 'Avenseguim',\n",
       " 'Avis',\n",
       " 'Baubillious',\n",
       " 'Bombarda',\n",
       " 'Bombarda Maxima',\n",
       " 'Brackium Emendo',\n",
       " 'Calvorio',\n",
       " 'Cantis',\n",
       " 'Capacious extremis',\n",
       " 'Carpe Retractum',\n",
       " 'Cave inimicum',\n",
       " 'Circumrota',\n",
       " 'Cistem Aperio',\n",
       " 'Colloportus',\n",
       " 'Colloshoo',\n",
       " 'Colovaria',\n",
       " 'Confringo',\n",
       " 'Confundo',\n",
       " 'Crinus Muto',\n",
       " 'Crucio',\n",
       " 'Defodio',\n",
       " 'Deletrius',\n",
       " 'Densaugeo',\n",
       " 'Deprimo',\n",
       " 'Depulso',\n",
       " 'Descendo',\n",
       " 'Diffindo',\n",
       " 'Diminuendo',\n",
       " 'Dissendium',\n",
       " 'Draconifors',\n",
       " 'Ducklifors',\n",
       " 'Duro',\n",
       " 'Ebublio',\n",
       " 'Engorgio',\n",
       " 'Engorgio Skullus',\n",
       " 'Entomorphis',\n",
       " 'Epoximise',\n",
       " 'Erecto',\n",
       " 'Evanesce',\n",
       " 'Evanesco',\n",
       " 'Everte Statum',\n",
       " 'Expecto Patronum',\n",
       " 'Expelliarmus',\n",
       " 'Expulso',\n",
       " 'Ferula',\n",
       " 'Fianto Duri',\n",
       " 'Finestra',\n",
       " 'Finite',\n",
       " 'Flagrante',\n",
       " 'Flagrate',\n",
       " 'Flintifors',\n",
       " 'Flipendo',\n",
       " 'Flipendo Tria',\n",
       " 'Fumos',\n",
       " 'Fumos Duo',\n",
       " 'Furnunculus',\n",
       " 'Geminio',\n",
       " 'Glacius',\n",
       " 'Glacius Duo',\n",
       " 'Glacius Tria',\n",
       " 'Glisseo',\n",
       " 'Harmonia Nectere Passus',\n",
       " 'Herbifors',\n",
       " 'Herbivicus',\n",
       " 'Homenum Revelio',\n",
       " 'Illegibilus',\n",
       " 'Immobulus',\n",
       " 'Impedimenta',\n",
       " 'Imperio',\n",
       " 'Impervius ',\n",
       " 'Incarcerous',\n",
       " 'Incendio',\n",
       " 'Incendio Tria',\n",
       " 'Inflatus',\n",
       " 'Informous',\n",
       " 'Locomotor Wibbly',\n",
       " 'Lacarnum Inflamari',\n",
       " 'Langlock',\n",
       " 'Lapifors',\n",
       " 'Legilimens',\n",
       " 'Levicorpus',\n",
       " 'Liberacorpus',\n",
       " 'Locomotor',\n",
       " 'Locomotor Mortis',\n",
       " 'Lumos',\n",
       " 'Lumos Duo',\n",
       " 'Lumos Maxima',\n",
       " 'Lumos Solem',\n",
       " 'Magicus Extremos',\n",
       " 'Melofors',\n",
       " 'Meteolojinx Recanto',\n",
       " 'Mimblewimble',\n",
       " 'Mobiliarbus',\n",
       " 'Mobilicorpus',\n",
       " 'Molliare',\n",
       " 'Morsmordre',\n",
       " 'Mucus ad Nauseam',\n",
       " 'Muffliato ',\n",
       " 'Multicorfors ',\n",
       " 'Mutatio Skullus',\n",
       " 'Nox',\n",
       " 'Nebulus',\n",
       " 'Oculus Reparo',\n",
       " 'Obliviate\\xa0',\n",
       " 'Obscuro',\n",
       " 'Oppugno ',\n",
       " 'Orbis',\n",
       " 'Orchideous',\n",
       " 'Oscausi',\n",
       " 'Pack',\n",
       " 'Papyrus Reparo',\n",
       " 'Partis Temporus',\n",
       " 'Periculum',\n",
       " 'Peskipiksi Pesternomi',\n",
       " 'Petrificus Totalus',\n",
       " 'Piertotum Locomotor',\n",
       " 'Piscifors',\n",
       " 'Point Me',\n",
       " 'Portus',\n",
       " 'Prior Incantato',\n",
       " 'Protego',\n",
       " 'Protego Diabolica',\n",
       " 'Protego horribilis',\n",
       " 'Protego Maxima',\n",
       " 'Protego totalum',\n",
       " 'Quietus',\n",
       " 'Redactum Skullus',\n",
       " 'Reducio',\n",
       " 'Reducto',\n",
       " 'Reparifors',\n",
       " 'Reverte',\n",
       " 'Relashio',\n",
       " 'Rennervate',\n",
       " 'Reparifarge',\n",
       " 'Reparo',\n",
       " 'Repello Muggletum',\n",
       " 'Repello Inimicum',\n",
       " 'Revelio',\n",
       " 'Rictusempra',\n",
       " 'Riddikulus',\n",
       " 'Salvio hexia',\n",
       " 'Scourgify',\n",
       " 'Sectumsempra',\n",
       " 'Serpensortia',\n",
       " 'Silencio',\n",
       " 'Skurge',\n",
       " 'Slugulus Eructo',\n",
       " 'Sonorus',\n",
       " 'Specialis Revelio',\n",
       " 'Spongify',\n",
       " 'Steleus',\n",
       " 'Stupefy',\n",
       " 'Surgito',\n",
       " 'Tarantallegra\\xa0',\n",
       " 'Tentaclifors',\n",
       " 'Tergeo',\n",
       " 'Titillando',\n",
       " 'Ventus',\n",
       " 'Ventus Duo',\n",
       " 'Vera Verto',\n",
       " 'Verdillious',\n",
       " 'Verdimillious',\n",
       " 'Vermiculus',\n",
       " 'Vermillious',\n",
       " 'Vipera Evanesca',\n",
       " 'Vulnera Sanentur',\n",
       " 'Waddiwasi',\n",
       " 'Wingardium Leviosa',\n",
       " 'Episkey']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the NaN cells with an empty string\n",
    "spells_df['Incantation'] = spells_df['Incantation'].fillna(\"\")\n",
    "\n",
    "# Get all spells\n",
    "spells = spells_df['Incantation'].unique().tolist() # Put all strs in the 'Incantation' column in a list\n",
    "spells = [spell for spell in spells if spell != ''] # Get all non-empty strs from the list, i.e. all the spells\n",
    "\n",
    "# Take a look at the spells\n",
    "spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067334d",
   "metadata": {},
   "source": [
    "### Creating the patterns to be added to the EntityRuler\n",
    "\n",
    "Recall from Wednesday's lesson that the patterns we add to an EntityRuler look like the following.\n",
    "\n",
    "`patterns = [{\"label\": \"GPE\", \"pattern\": \"Aars\"}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95345f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the pattern to be added to the ruler\n",
    "patterns = [{\"label\":\"SPELL\", \"pattern\":spell} for spell in spells]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865668ad",
   "metadata": {},
   "source": [
    "Now that we have the patterns ready, we can add them to an EntityRuler and add the ruler as a new pipe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087cb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EntityRuler and add the patterns to the ruler\n",
    "entruler_nlp = spacy.blank('en') # Create a blank English model\n",
    "ruler = entruler_nlp.add_pipe(\"entity_ruler\") \n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e938c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntRulerModel Wingardium Leviosa SPELL\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"Ron Weasley: Wingardium Leviosa! Hermione Granger: You're saying it wrong. \n",
    "It's Wing-gar-dium Levi-o-sa, make the 'gar' nice and long. \n",
    "Ron Weasley: You do it, then, if you're so clever\"\"\"\n",
    "doc = entruler_nlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    print('EntRulerModel', ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c60d0bf",
   "metadata": {},
   "source": [
    "In this model, we have basically hard written all spell strings in the EntityRuler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c69b3",
   "metadata": {},
   "source": [
    "## Train a NLP model using ML to identify the spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb6c0b",
   "metadata": {},
   "source": [
    "The format of the training data will look like the following. It is a list of tuples. In each tuple, the first element is the text string containing spells and the second element is a dictionary. The key of the dictionary is 'entities'. The value is a list of lists. In each list, we find the starting index, ending index and the label of the spell(s) found in the text string. \n",
    "\n",
    "`[\n",
    "('Oculus Reparo', {'entities': [[0, 13, 'SPELL']]}),\n",
    "('Alohomora', {'entities': [[0, 9, 'SPELL']]})\n",
    "]`\n",
    "\n",
    "The text strings we use for the training are from the 'Sentence' column of the film_spells dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c681fc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>identified_spells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I should've known that you would be here, Prof...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Are the rumors true, Albus?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I'm afraid so, professor.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>The good and the bad.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>How fast is it, Harry?</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>I solemnly swear that I am up to no good.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Mischief managed.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4928 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Character                                           Sentence  \\\n",
       "0     Dumbledore  I should've known that you would be here, Prof...   \n",
       "1     McGonagall                Good evening, Professor Dumbledore.   \n",
       "2     McGonagall                        Are the rumors true, Albus?   \n",
       "3     Dumbledore                          I'm afraid so, professor.   \n",
       "4     Dumbledore                              The good and the bad.   \n",
       "...          ...                                                ...   \n",
       "4923    HERMIONE                             How fast is it, Harry?   \n",
       "4924       HARRY                                             Lumos.   \n",
       "4925       HARRY          I solemnly swear that I am up to no good.   \n",
       "4926       HARRY                                  Mischief managed.   \n",
       "4927       HARRY                                               Nox.   \n",
       "\n",
       "     movie_number identified_spells  \n",
       "0          film 1               NaN  \n",
       "1          film 1               NaN  \n",
       "2          film 1               NaN  \n",
       "3          film 1               NaN  \n",
       "4          film 1               NaN  \n",
       "...           ...               ...  \n",
       "4923       film 3               NaN  \n",
       "4924       film 3             Lumos  \n",
       "4925       film 3               NaN  \n",
       "4926       film 3               NaN  \n",
       "4927       film 3               Nox  \n",
       "\n",
       "[4928 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the film_spells df\n",
    "film_spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c362e54",
   "metadata": {},
   "source": [
    "Since we have hard written all spell strings in the EntityRuler and give them the label 'SPELL', we could just use this model to generate labeled data as our training data and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ba2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mearacox/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('For example: Oculus Reparo.', {'entities': [[13, 26, 'SPELL']]}),\n",
       " ('Alohomora Get in Alohomora?',\n",
       "  {'entities': [[0, 9, 'SPELL'], [17, 26, 'SPELL']]}),\n",
       " ('Wingardium Leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('Wingardium Leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('Wingardium Leviosa!', {'entities': [[0, 18, 'SPELL']]}),\n",
       " (\"Neville, I'm really, really sorry about this  Petrificus Totalus.\",\n",
       "  {'entities': [[46, 64, 'SPELL']]}),\n",
       " ('Alohomora.', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('Alohomora!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('Oculus Reparo.', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('Peskipiksi Pesternomi!', {'entities': [[0, 21, 'SPELL']]}),\n",
       " ('Immobulus!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('Vera Verto.', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Vera Verto.', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Vera Verto!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Finite Incantatem!', {'entities': [[0, 6, 'SPELL']]}),\n",
       " ('Brackium Emendo!', {'entities': [[0, 15, 'SPELL']]}),\n",
       " ('Expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Two... Everte Statum!', {'entities': [[7, 20, 'SPELL']]}),\n",
       " ('Rictusempra!', {'entities': [[0, 11, 'SPELL']]}),\n",
       " ('Serpensortia!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Alarte Ascendare!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Vipera Evanesca.', {'entities': [[0, 15, 'SPELL']]}),\n",
       " ('Wingardium Leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('Cistem Aperio!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('Arania Exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('Arania Exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('Arania Exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('Lumos Maxima... Lumos Maxima... Lumos Maxima... Lumos... MAXIMA!',\n",
       "  {'entities': [[0, 12, 'SPELL'],\n",
       "    [16, 28, 'SPELL'],\n",
       "    [32, 44, 'SPELL'],\n",
       "    [48, 53, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Listen: Riddikulus!', {'entities': [[8, 18, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('Then speak the incantation, Expecto Patronum.',\n",
       "  {'entities': [[28, 44, 'SPELL']]}),\n",
       " ('Expecto Patronum.', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Expecto Patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Expecto Patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Expecto Patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Nox.', {'entities': [[0, 3, 'SPELL']]}),\n",
       " ('Expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('Expecto Patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Immobulus!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('Expecto Patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('Bombarda!', {'entities': [[0, 8, 'SPELL']]}),\n",
       " ('Lumos.', {'entities': [[0, 5, 'SPELL']]}),\n",
       " ('Nox.', {'entities': [[0, 3, 'SPELL']]})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk # for sentence tokenization\n",
    "nltk.download('punkt')\n",
    "def generate_labeled_data(ls_sents): # the input will be a list of strings\n",
    "    text = ' '.join(ls_sents)\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    labeled_data = []\n",
    "    for sent in sents:\n",
    "        doc = entruler_nlp(sent) # create a doc object\n",
    "        if doc.ents != (): # if there is at least one entity identified\n",
    "            labeled_data.append((sent, {\"entities\":[[ent.start_char, ent.end_char, ent.label_] for ent in doc.ents]}))\n",
    "    return labeled_data       \n",
    "\n",
    "# Assign the result from the function to a new variable\n",
    "training_validation_data = generate_labeled_data(film_spells['Sentence'].tolist())\n",
    "\n",
    "# Take a look at the labeled data\n",
    "training_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a8751",
   "metadata": {},
   "source": [
    "spaCy 3 requires that our data be stored in the proprietary `.spacy` format. To do that we need to use the `DocBin` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710c8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin \n",
    "\n",
    "db = DocBin() \n",
    "\n",
    "for text, annot in training_validation_data[:19*2]: # Get the first 38 tuples as the training data\n",
    "    doc = entruler_nlp(text) # create a doc object\n",
    "    doc.ents = [doc.char_span(ent[0], ent[1], label=ent[2]) for ent in annot['entities']]\n",
    "    db.add(doc)\n",
    "db.to_disk(f\"./train_spells.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e548230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, annot in training_validation_data[19*2:]: # Get the rest tuples as the validation data\n",
    "    doc = entruler_nlp(text) \n",
    "    doc.ents = [doc.char_span(ent[0], ent[1], label=ent[2]) for ent in annot['entities']]\n",
    "    db.add(doc)\n",
    "db.to_disk(f\"./valid_spells.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73251",
   "metadata": {},
   "source": [
    "Now we can finally start training our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29b396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config --lang en --pipeline ner config.cfg --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "612b79cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output/spells-model\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output/spells-model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     70.00   33.99   26.80   46.43    0.34\n",
      "141     200          1.46    584.26   98.18  100.00   96.43    0.98\n",
      "341     400          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "541     600          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "741     800          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "941    1000          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "1141    1200          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "1341    1400          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "1541    1600          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "1741    1800          0.00      0.00   98.18  100.00   96.43    0.98\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/spells-model/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output/spells-model/ --paths.train ./train_spells.spacy --paths.dev ./valid_spells.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0e1b6",
   "metadata": {},
   "source": [
    "Now let's finally run our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44239291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model_best = spacy.load('./output/spells-model/model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926983c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animates SPELL\n",
      "Aparecium - SPELL\n",
      "Your SPELL\n",
      "Defodio - SPELL\n",
      "Sometimes you SPELL\n",
      "of SPELL\n",
      "Descendo SPELL\n",
      "Specialis Revelio SPELL\n",
      "Reveals SPELL\n",
      "Meteolojinx Recanto SPELL\n",
      "46 SPELL\n",
      "Protego Totalum SPELL\n",
      "Strengthens SPELL\n",
      "Freezes SPELL\n",
      "Stop SPELL\n",
      "Obscuro - SPELL\n",
      "Blindfolds SPELL\n",
      "Reducto SPELL\n",
      "Explodes SPELL\n",
      "Anapneo - SPELL\n",
      "Clears SPELL\n",
      "41 SPELL\n",
      "Locomotor Mortis SPELL\n",
      "Southwest Airlines SPELL\n",
      "40 SPELL\n",
      "Aguamenti - SPELL\n",
      "Shoot SPELL\n",
      "Avada Kedavra SPELL\n",
      "Killing Curse SPELL\n",
      "Repelo Muggletum SPELL\n",
      "Repels SPELL\n",
      "Sounds SPELL\n",
      "Muggle SPELL\n",
      "Stupefy SPELL\n",
      "Since SPELL\n",
      "Deathly Hallows SPELL\n"
     ]
    }
   ],
   "source": [
    "# Let's try our model on this long text string\n",
    "test_text = \"\"\"53. Imperio - Makes target obey every command But only for really, really funny pranks. 52. Piertotum Locomotor - Animates statues On one hand, this is awesome. On the other, someone would use this to scare me.\n",
    "\n",
    "51. Aparecium - Make invisible ink appear\n",
    "\n",
    "Your notes will be so much cooler.\n",
    "\n",
    "50. Defodio - Carves through stone and steel\n",
    "\n",
    "Sometimes you need to get the eff out of there.\n",
    "\n",
    "49. Descendo - Moves objects downward\n",
    "\n",
    "You'll never have to get a chair to reach for stuff again.\n",
    "\n",
    "48. Specialis Revelio - Reveals hidden magical properties in an object\n",
    "\n",
    "I want to know what I'm eating and if it's magical.\n",
    "\n",
    "47. Meteolojinx Recanto - Ends effects of weather spells\n",
    "\n",
    "Otherwise, someone could make it sleet in your bedroom forever.\n",
    "\n",
    "46. Cave Inimicum/Protego Totalum - Strengthens an area's defenses\n",
    "\n",
    "Helpful, but why are people trying to break into your campsite?\n",
    "\n",
    "45. Impedimenta - Freezes someone advancing toward you\n",
    "\n",
    "\"Stop running at me! But also, why are you running at me?\"\n",
    "\n",
    "44. Obscuro - Blindfolds target\n",
    "\n",
    "Finally, we don't have to rely on \"No peeking.\"\n",
    "\n",
    "43. Reducto - Explodes object\n",
    "\n",
    "The \"raddest\" of all spells.\n",
    "\n",
    "42. Anapneo - Clears someone's airway\n",
    "\n",
    "This could save a life, but hopefully you won't need it.\n",
    "\n",
    "41. Locomotor Mortis - Leg-lock curse\n",
    "\n",
    "Good for footraces and Southwest Airlines flights.\n",
    "\n",
    "40. Geminio - Creates temporary, worthless duplicate of any object\n",
    "\n",
    "You could finally live your dream of lying on a bed of marshmallows, and you'd only need one to start.\n",
    "\n",
    "39. Aguamenti - Shoot water from wand\n",
    "\n",
    "No need to replace that fire extinguisher you never bought.\n",
    "\n",
    "38. Avada Kedavra - The Killing Curse\n",
    "\n",
    "One word: bugs.\n",
    "\n",
    "37. Repelo Muggletum - Repels Muggles\n",
    "\n",
    "Sounds elitist, but seriously, Muggles ruin everything. Take it from me, a Muggle.\n",
    "\n",
    "36. Stupefy - Stuns target\n",
    "\n",
    "Since this is every other word of the \"Deathly Hallows\" script, I think it's pretty useful.\"\"\"\n",
    "\n",
    "# Create a doc object out of the text string using the trained model\n",
    "doc = model_best(test_text)\n",
    "\n",
    "# Find out the entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e2888",
   "metadata": {},
   "source": [
    "Let's also try the model we created with an EntityRuler with all spell names hard written in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e12b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imperio SPELL\n",
      "Piertotum Locomotor SPELL\n",
      "Aparecium SPELL\n",
      "Defodio SPELL\n",
      "Descendo SPELL\n",
      "Specialis Revelio SPELL\n",
      "Meteolojinx Recanto SPELL\n",
      "Protego SPELL\n",
      "Impedimenta SPELL\n",
      "Obscuro SPELL\n",
      "Reducto SPELL\n",
      "Anapneo SPELL\n",
      "Locomotor Mortis SPELL\n",
      "Geminio SPELL\n",
      "Aguamenti SPELL\n",
      "Avada Kedavra SPELL\n",
      "Stupefy SPELL\n"
     ]
    }
   ],
   "source": [
    "# Create a doc object out of the text string using the EntityRuler model\n",
    "doc = entruler_nlp(test_text)\n",
    "\n",
    "# Find out the entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e49ed",
   "metadata": {},
   "source": [
    "It seems in this example our EntityRuler model performs better than our trained model. Why do we think that is?\n",
    "\n",
    "Part of the reason we aren't getting better results is something that Ines Montani describes in this Stack Overflow answer https://stackoverflow.com/questions/50580262/how-to-use-spacy-to-create-a-new-entity-and-learn-only-from-keyword-list/50603247#50603247\n",
    "\n",
    "\"The advantage of training the named entity recognizer to detect SPECIES in your text is that the model won't only be able to recognise your examples, but also generalise and recognise other species in context. If you only want to find a fixed set of terms and not more, a simpler, rule-based approach might work better for you.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01473f",
   "metadata": {},
   "source": [
    "# References\n",
    "McCormick, C. (2016, April 19). Word2Vec Tutorial - The Skip-Gram Model. Retrieved from http://www.mccormickml.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
