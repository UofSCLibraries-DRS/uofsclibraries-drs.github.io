Traceback (most recent call last):
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Users/mearacox/opt/anaconda3/lib/python3.9/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
text = """Hi there, how are you? I am doing well, thanks for asking. It is really nice out today!
Think it will rain tomorrow? The weather caster predicted a 40% chance of precipitation. Maybe, I will bring a jacket with me tomorrow just in case."""
sentence_tokens = sent_tokenize(text)
print("Sentence Tokens: " + str(sentence_tokens))
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mLookupError[0m                               Traceback (most recent call last)
Input [0;32mIn [3][0m, in [0;36m<cell line: 3>[0;34m()[0m
[1;32m      1[0m text [38;5;241m=[39m [38;5;124m"""[39m[38;5;124mHi there, how are you? I am doing well, thanks for asking. It is really nice out today![39m
[1;32m      2[0m [38;5;124mThink it will rain tomorrow? The weather caster predicted a 40[39m[38;5;132;01m% c[39;00m[38;5;124mhance of precipitation. Maybe, I will bring a jacket with me tomorrow just in case.[39m[38;5;124m"""[39m
[0;32m----> 3[0m sentence_tokens [38;5;241m=[39m [43msent_tokenize[49m[43m([49m[43mtext[49m[43m)[49m
[1;32m      4[0m [38;5;28mprint[39m([38;5;124m"[39m[38;5;124mSentence Tokens: [39m[38;5;124m"[39m [38;5;241m+[39m [38;5;28mstr[39m(sentence_tokens))

File [0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py:106[0m, in [0;36msent_tokenize[0;34m(text, language)[0m
[1;32m     96[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21msent_tokenize[39m(text, language[38;5;241m=[39m[38;5;124m"[39m[38;5;124menglish[39m[38;5;124m"[39m):
[1;32m     97[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[1;32m     98[0m [38;5;124;03m    Return a sentence-tokenized copy of *text*,[39;00m
[1;32m     99[0m [38;5;124;03m    using NLTK's recommended sentence tokenizer[39;00m
[0;32m   (...)[0m
[1;32m    104[0m [38;5;124;03m    :param language: the model name in the Punkt corpus[39;00m
[1;32m    105[0m [38;5;124;03m    """[39;00m
[0;32m--> 106[0m     tokenizer [38;5;241m=[39m [43mload[49m[43m([49m[38;5;124;43mf[39;49m[38;5;124;43m"[39;49m[38;5;124;43mtokenizers/punkt/[39;49m[38;5;132;43;01m{[39;49;00m[43mlanguage[49m[38;5;132;43;01m}[39;49;00m[38;5;124;43m.pickle[39;49m[38;5;124;43m"[39;49m[43m)[49m
[1;32m    107[0m     [38;5;28;01mreturn[39;00m tokenizer[38;5;241m.[39mtokenize(text)

File [0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:750[0m, in [0;36mload[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)[0m
[1;32m    747[0m     [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124m<<Loading [39m[38;5;132;01m{[39;00mresource_url[38;5;132;01m}[39;00m[38;5;124m>>[39m[38;5;124m"[39m)
[1;32m    749[0m [38;5;66;03m# Load the resource.[39;00m
[0;32m--> 750[0m opened_resource [38;5;241m=[39m [43m_open[49m[43m([49m[43mresource_url[49m[43m)[49m
[1;32m    752[0m [38;5;28;01mif[39;00m [38;5;28mformat[39m [38;5;241m==[39m [38;5;124m"[39m[38;5;124mraw[39m[38;5;124m"[39m:
[1;32m    753[0m     resource_val [38;5;241m=[39m opened_resource[38;5;241m.[39mread()

File [0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:876[0m, in [0;36m_open[0;34m(resource_url)[0m
[1;32m    873[0m protocol, path_ [38;5;241m=[39m split_resource_url(resource_url)
[1;32m    875[0m [38;5;28;01mif[39;00m protocol [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m [38;5;129;01mor[39;00m protocol[38;5;241m.[39mlower() [38;5;241m==[39m [38;5;124m"[39m[38;5;124mnltk[39m[38;5;124m"[39m:
[0;32m--> 876[0m     [38;5;28;01mreturn[39;00m [43mfind[49m[43m([49m[43mpath_[49m[43m,[49m[43m [49m[43mpath[49m[43m [49m[38;5;241;43m+[39;49m[43m [49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43m"[39;49m[43m][49m[43m)[49m[38;5;241m.[39mopen()
[1;32m    877[0m [38;5;28;01melif[39;00m protocol[38;5;241m.[39mlower() [38;5;241m==[39m [38;5;124m"[39m[38;5;124mfile[39m[38;5;124m"[39m:
[1;32m    878[0m     [38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:[39;00m
[1;32m    879[0m     [38;5;28;01mreturn[39;00m find(path_, [[38;5;124m"[39m[38;5;124m"[39m])[38;5;241m.[39mopen()

File [0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:583[0m, in [0;36mfind[0;34m(resource_name, paths)[0m
[1;32m    581[0m sep [38;5;241m=[39m [38;5;124m"[39m[38;5;124m*[39m[38;5;124m"[39m [38;5;241m*[39m [38;5;241m70[39m
[1;32m    582[0m resource_not_found [38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00mmsg[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;124m"[39m
[0;32m--> 583[0m [38;5;28;01mraise[39;00m [38;5;167;01mLookupError[39;00m(resource_not_found)

[0;31mLookupError[0m: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/PY3/english.pickle[0m

  Searched in:
    - '/Users/mearacox/nltk_data'
    - '/Users/mearacox/opt/anaconda3/nltk_data'
    - '/Users/mearacox/opt/anaconda3/share/nltk_data'
    - '/Users/mearacox/opt/anaconda3/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
    - ''
**********************************************************************

LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/PY3/english.pickle[0m

  Searched in:
    - '/Users/mearacox/nltk_data'
    - '/Users/mearacox/opt/anaconda3/nltk_data'
    - '/Users/mearacox/opt/anaconda3/share/nltk_data'
    - '/Users/mearacox/opt/anaconda3/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
    - ''
**********************************************************************


